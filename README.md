# ğŸµ DeepFake Guard - AI Audio Detection System

Advanced deepfake audio detection system powered by CNN achieving **90% accuracy**. Modern React SPA with real-time analysis, microphone recording, and comprehensive reporting.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.11+-green.svg)
![TensorFlow](https://img.shields.io/badge/tensorflow-2.10+-orange.svg)
![React](https://img.shields.io/badge/react-18.2-blue.svg)

## âœ¨ Features

### ğŸ¯ Core Capabilities
- **ğŸ¤– Advanced CNN Model** - 90% accuracy, 89.8% F1-score
- **âš›ï¸ Modern React Interface** - Single Page Application with Vite
- **ğŸ¤ Microphone Recording** - Record and analyze audio in-browser
- **ğŸ“ Multi-Format Support** - WAV, MP3, FLAC, M4A, OGG, WEBM
- **ğŸ”„ WebM Auto-Conversion** - FFmpeg integration for Chrome compatibility
- **ğŸ“Š Visual Analysis** - Mel-spectrogram and waveform visualization
- **ğŸ“„ Report Generation** - Detailed TXT reports with technical metrics
- **ğŸ”Š Audio Playback** - Built-in player for recorded/uploaded files
- **ğŸ‘¤ User Authentication** - Secure login/register system
- **ğŸ“œ Analysis History** - Track all analyses per user
- **ğŸ˜ PostgreSQL Database** - Production-ready database system

### âš™ï¸ Technical Features
- **REST API** - Flask backend with JSON responses
- **Optimized Threshold** - Fine-tuned detection (0.0001)
- **Responsive Design** - Bootstrap 5 + React components
- **Modern Tooling** - Vite for fast builds and HMR
- **Auto Cleanup** - Automatic file management
- **Secure Sessions** - HTTPOnly cookies, CSRF protection

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites
```bash
Python >= 3.11
PostgreSQL >= 14
Node.js >= 18 (for frontend development)
FFmpeg (for audio conversion)
```

### ğŸ“¦ Installation

#### 1ï¸âƒ£ Clone Repository
```bash
git clone <repository-url>
cd "deepfake guard"
```

#### 2ï¸âƒ£ Setup Python Environment
```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

#### 3ï¸âƒ£ Configure Database
```bash
# Create PostgreSQL database
psql -U postgres -c "CREATE DATABASE deepfake_guard;"

# Configure .env file
cp .env.example .env
# Edit .env with your PostgreSQL credentials

# Initialize database tables
python migrate_to_postgres.py
```

#### 4ï¸âƒ£ Install FFmpeg
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt-get install ffmpeg

# Windows - Download from https://ffmpeg.org/download.html
```

#### 5ï¸âƒ£ Run Application
```bash
python app.py
```

### ğŸŒ Access Points
- **Main App**: http://localhost:8080/
- **Login**: http://localhost:8080/login
- **Register**: http://localhost:8080/register

### ğŸ‘¥ Default Users
| Username | Password | Role |
|----------|----------|------|
| admin | admin123 | Administrator |
| demo | demo123 | Demo User |
| user | user123 | Standard User |

## ğŸ“Š Model Performance

| Metric | Value |
|--------|-------|
| **Accuracy** | **90.0%** |
| **F1-Score** | **89.8%** |
| **Precision** | 87.9% |
| **Recall** | 92.1% |
| **ROC-AUC** | 0.966 |

### ğŸ“ˆ Dataset
- **Training**: 13,957 samples
- **Validation**: 2,826 samples
- **Testing**: 1,089 samples
- **Total**: 17,872 files (balanced 50/50 real/fake)

## ğŸ¯ Usage Guide

### ğŸŒ Web Interface

1. **Login** - Use default credentials or register new account
2. **Upload Audio** (Option A):
   - Drag & drop file or click to browse
   - Supports: WAV, MP3, FLAC, M4A, OGG, WEBM
   - Max size: 16MB
3. **Record Audio** (Option B):
   - Click "Start Recording"
   - Speak into microphone
   - Click "Stop Recording"
4. **Analyze** - Click "Analyze Speech"
5. **Review Results**:
   - View prediction (REAL/FAKE)
   - Check confidence score
   - See spectrogram visualization
   - Play audio
   - Download detailed report

### ğŸ Python API

```python
import tensorflow as tf
import librosa
import numpy as np

# Load model
model = tf.keras.models.load_model('results/best_advanced_cnn_model.h5')

# Process audio
audio, sr = librosa.load('audio.wav', sr=16000, duration=2.0)
mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)
mel_spec = np.expand_dims(mel_spec, axis=-1)
mel_spec = np.expand_dims(mel_spec, axis=0)

# Predict
prediction = model.predict(mel_spec)[0][0]
threshold = 0.0001
is_fake = prediction > threshold
confidence = abs(prediction - threshold) * 10000

print(f"Result: {'DEEPFAKE' if is_fake else 'REAL'}")
print(f"Confidence: {confidence:.1f}%")
```

## ğŸ“ Project Structure

```
deepfake guard/
â”œâ”€â”€ ğŸ Backend
â”‚   â”œâ”€â”€ app.py                      # Main Flask application
â”‚   â”œâ”€â”€ database.py                 # SQLAlchemy models
â”‚   â”œâ”€â”€ clear_users.py              # Database utility
â”‚   â”œâ”€â”€ migrate_to_postgres.py      # DB migration script
â”‚   â””â”€â”€ .env                        # Environment variables
â”‚
â”œâ”€â”€ ğŸ§  ML Model
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ best_advanced_cnn_model.h5  # Trained model (90%)
â”‚       â””â”€â”€ advanced_cnn_90percent_accuracy.h5
â”‚
â”œâ”€â”€ âš›ï¸ Frontend (React + Vite)
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ App.jsx             # Main component
â”‚       â”‚   â”œâ”€â”€ App.css             # Styles
â”‚       â”‚   â””â”€â”€ main.jsx            # Entry point
â”‚       â”œâ”€â”€ package.json
â”‚       â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ ğŸ¨ Templates
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ react_app.html          # React wrapper
â”‚   â”‚   â”œâ”€â”€ login.html              # Login page
â”‚   â”‚   â””â”€â”€ register.html           # Register page
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ logo.png                # Application logo
â”‚       â””â”€â”€ react-dist/             # Built React assets
â”‚
â”œâ”€â”€ ğŸ“ Data Directories
â”‚   â”œâ”€â”€ training/                   # Training audio files
â”‚   â”œâ”€â”€ validation/                 # Validation audio files
â”‚   â”œâ”€â”€ testing/                    # Testing audio files
â”‚   â””â”€â”€ uploads/                    # Temporary uploads
â”‚
â””â”€â”€ ğŸ“„ Documentation
    â”œâ”€â”€ README.md                   # This file
    â”œâ”€â”€ requirements.txt            # Python dependencies
    â””â”€â”€ .env.example                # Environment template
```

## ğŸ”§ Configuration

### ğŸ—„ï¸ Database Setup

Create `.env` file:
```bash
DATABASE_URL=postgresql://postgres:your_password@localhost:5432/deepfake_guard
SECRET_KEY=your-secret-key-here
FLASK_ENV=development
DEBUG=True
```

Initialize database:
```bash
psql -U postgres -c "CREATE DATABASE deepfake_guard;"
python migrate_to_postgres.py
```

### ğŸ¥ FFmpeg Configuration

Required for WebM format support (Chrome recordings):
```bash
# Verify installation
ffmpeg -version

# Should output FFmpeg version info
```

## ğŸ› ï¸ Development

### Frontend Development
```bash
cd frontend

# Install dependencies
npm install

# Development server (HMR enabled)
npm run dev

# Production build
npm run build
```

### Database Management
```bash
# Clear all users
python clear_users.py

# Recreate tables
python migrate_to_postgres.py
```

### Debug Mode
```bash
# Flask debug mode enabled by default
python app.py
```

## ğŸ§  Technical Architecture

### Model Details
- **Architecture**: Advanced CNN with residual connections
- **Input Shape**: 128x63x1 (mel-spectrogram)
- **Layers**: Conv2D, BatchNorm, MaxPooling, Dense
- **Activation**: ReLU, Sigmoid output
- **Optimizer**: Adam
- **Loss**: Binary crossentropy

### Audio Processing Pipeline
1. **Load**: Read audio file (librosa)
2. **Resample**: Convert to 16kHz
3. **Trim**: Extract first 2 seconds
4. **Transform**: Generate mel-spectrogram (128 mel bins)
5. **Normalize**: Min-max scaling
6. **Predict**: CNN inference
7. **Threshold**: Apply optimal threshold (0.0001)

### API Endpoints

#### `POST /upload`
Upload and analyze audio file
- **Input**: Multipart form data with audio file
- **Output**: JSON with prediction results

#### `POST /generate_report`
Generate detailed analysis report
- **Input**: JSON with analysis metadata
- **Output**: TXT file with technical details

#### `GET /downloads/<filename>`
Serve uploaded audio for playback
- **Input**: Filename parameter
- **Output**: Audio file stream

## ğŸš€ Production Deployment

### Using Gunicorn
```bash
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:8080 app:app
```

### Environment Variables
```bash
export DATABASE_URL=postgresql://user:pass@host:5432/dbname
export SECRET_KEY=production-secret-key
export FLASK_ENV=production
export DEBUG=False
```

### Nginx Configuration (Optional)
```nginx
server {
    listen 80;
    server_name yourdomain.com;

    location / {
        proxy_pass http://127.0.0.1:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

## âš ï¸ Important Notes

- **Audio Length**: System processes first 2 seconds of audio
- **File Cleanup**: Uploaded files are automatically deleted after analysis
- **Session Timeout**: 24 hours by default
- **Max Upload Size**: 16MB per file
- **Supported Browsers**: Chrome, Firefox, Safari, Edge (latest versions)

## ğŸ”’ Security Features

- âœ… File validation and sanitization
- âœ… Secure filename handling
- âœ… SQL injection protection (SQLAlchemy ORM)
- âœ… XSS protection (Flask auto-escaping)
- âœ… CSRF protection (session tokens)
- âœ… HTTPOnly cookies
- âœ… Password hashing (Werkzeug)

## ğŸ› Troubleshooting

### Database Connection Error
```bash
# Check PostgreSQL is running
brew services list  # macOS
sudo systemctl status postgresql  # Linux

# Verify credentials in .env
psql -U postgres -d deepfake_guard
```

### FFmpeg Not Found
```bash
# Add to PATH or install
which ffmpeg  # Should return path
```

### Module Not Found
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ™ Acknowledgments

- **TensorFlow** - Deep learning framework
- **Librosa** - Audio processing library
- **Flask** - Web framework
- **React** - UI library
- **Vite** - Build tool
- **Bootstrap** - CSS framework
- **PostgreSQL** - Database system

---

**Built with â¤ï¸ for combating deepfake audio**  
**Last Updated:** January 16, 2026

## ğŸ† Features

### Core Features
- **Advanced CNN Model**: 90% accuracy, 89.8% F1-score
- **Modern React Interface**: Single Page Application with responsive design
- **Microphone Recording**: Record and analyze audio directly in browser
- **Multiple Audio Formats**: WAV, MP3, FLAC, M4A, OGG, WEBM support
- **WebM Support**: Automatic conversion using FFmpeg
- **Real-time Analysis**: Live processing with progress indicators
- **Visual Analysis**: Mel-spectrogram and waveform visualization
- **Report Generation**: TXT format reports with technical details
- **Audio Playback**: Built-in player for uploaded/recorded audio
- **User Authentication**: Secure login/register system
- **Analysis History**: Track all analyses per user
- **PostgreSQL Database**: Production-ready database system

### Technical Features
- **Production Ready**: Flask REST API backend
- **Optimal Threshold**: Fine-tuned detection threshold (0.0001)
- **Responsive Design**: Bootstrap 5 + React
- **React + Vite**: Modern frontend build tooling
- **Auto File Cleanup**: Automatic uploaded file management
- **Session Management**: Secure user sessions

## ğŸš€ Quick Start

### Prerequisites
```bash
Python >= 3.11
Node.js >= 18 (for React development)
FFmpeg (for audio conversion)
pip >= 23.0
```

### Installation
```bash
# Clone the repository
git clone <repository-url>
cd "deepfake guard"

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux
# OR
venv\Scripts\activate     # On Windows

# Install Python dependencies
pip install -r requirements.txt

# Run the web application
python app.py
```

### React Development (Optional)
```bash
# Navigate to frontend directory
cd frontend

# Install Node dependencies
npm install

# Development mode
npm run dev

# Build for production
npm run build
```

### Access
```
ğŸŒ Web Interface: http://localhost:8080/
ğŸ” Login Page: http://localhost:8080/login
ğŸ“± Network Access: http://YOUR_IP:8080
```

## ğŸ“Š Model Performance

| Metric | Value |
|--------|-------|
| **Accuracy** | **90.0%** |
| **F1-Score** | **89.8%** |
| **Precision** | 87.9% |
| **Recall** | 92.1% |
| **ROC-AUC** | 0.966 |

## ğŸ¯ Usage

### Web Interface
1. Open http://localhost:8080 in your browser
2. Login with default credentials or register
3. **Option A - Upload File:**
   - Drag & drop audio file or click to browse
   - Supported formats: WAV, MP3, FLAC, M4A, OGG, WEBM
4. **Option B - Record Audio:**
   - Click "Start Recording"
   - Speak into microphone
   - Click "Stop Recording"
5. Click "Analyze Speech"
6. View results with spectrogram visualization
7. Play audio, download report, or analyze another

### Default Users
```
Username: demo / Password: demo123
Username: admin / Password: admin123
Username: mert / Password: mert123
```

### Python API
```python
import tensorflow as tf
import numpy as np
import librosa

# Load model and scaler
model = tf.keras.models.load_model('results/best_advanced_cnn_model.h5')

# Load and process audio
audio, sr = librosa.load('audio.wav', sr=16000)
mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)

# Predict with optimal threshold
prediction = model.predict(mel_spec)
is_fake = prediction > 0.0001  # Optimal threshold
confidence = abs(prediction - 0.0001) * 100
```

## ğŸ“ Project Structure

```
deepfake guard/
â”œâ”€â”€ app.py                          # Main Flask application
â”œâ”€â”€ database.py                     # Database models & setup
â”œâ”€â”€ clear_users.py                  # Utility to clear database users
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ best_advanced_cnn_model.h5 # Trained model (90% accuracy)
â”‚   â”œâ”€â”€ feature_scaler.pkl         # Feature scaler
â”‚   â””â”€â”€ *.pkl                      # Other model artifacts
â”œâ”€â”€ frontend/                       # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx                # Main React component
â”‚   â”‚   â”œâ”€â”€ App.css                # React styles
â”‚   â”‚   â””â”€â”€ main.jsx               # React entry point
â”‚   â”œâ”€â”€ package.json               # Node dependencies
â”‚   â””â”€â”€ vite.config.js             # Vite configuration
â”œâ”€â”€ templates/                      # Flask templates
â”‚   â”œâ”€â”€ index.html                 # Traditional interface
â”‚   â”œâ”€â”€ react_app.html             # React wrapper
â”‚   â”œâ”€â”€ login.html                 # Login page
â”‚   â””â”€â”€ register.html              # Registration page
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ react_app.html             # Main React wrapper
â”‚   â”œâ”€â”€ login.html                 # Login page
â”‚   â””â”€â”€ register.html              # Registration page
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/style.css              # Shared styles
â””â”€â”€ README.md                      # This file
```

## ğŸ”§ Configuration

### Database
The application uses PostgreSQL. Configure your database connection in `.env` file:

```bash
DATABASE_URL=postgresql://postgres:your_password@localhost:5432/deepfake_guard
```

Create the database:
```bash
psql -U postgres -c "CREATE DATABASE deepfake_guard;"
python migrate_to_postgres.py
```

### FFmpeg
FFmpeg is required for WebM audio conversion:
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt-get install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

## ğŸ› ï¸ Development

### Clear Database
```bash
python clear_users.py
```

### Rebuild React App
```bash
cd frontend
npm run build
```

### Run in Development Mode
```bash
# Flask debug mode is enabled by default
python app.py
```

## ğŸ§  Technical Details

### Model Architecture
- **Type**: Advanced Convolutional Neural Network
- **Input**: Mel-spectrograms (128x63x1)
- **Features**: Residual connections, attention mechanisms
- **Optimization**: Adam optimizer with optimal threshold (0.0001)

### Audio Processing
- **Sample Rate**: 16 kHz
- **Duration**: 2 seconds
- **Features**: Mel-spectrograms with 128 mel bins
- **Normalization**: Min-max scaling

### Running in Development Mode
```bash
# With debug enabled
python app.py
```

### Dataset Information
- **Training samples**: 13,957 audio files
- **Validation samples**: 2,826 audio files
- **Test samples**: 1,089 audio files
- **Total dataset**: 17,872 audio files (50% real, 50% fake) Testing
```bash
python test_pipeline.py
```

### Model Analysis
```bash
python complete_analysis.py
```

## ğŸ“ˆ Results

The system has been tested on a balanced dataset and achieves:
- **90% accuracy** on test data
- **Real audio detection**: 92.1%
- **Fake audio detection**: 87.9%
- **Production ready** performance

## ğŸš€ Deployment

### Local Development
```bash
python app_simple.py
```

### Produc.py
```

### Production (with Gunicorn)
```bash
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:8080 app:app
```

### Docker Deployment (Optional)
```bash
# Build image
docker build -t deepfake-detector .

# Run container
docker run -p 8080:8080 deepfake-detector

### Endpoints

#### `POST /upload`
Upload and analyze audio file.

**Request**: Multipart form with audio file
**Response**: JSON with detection results

#### `POST /generate_report`
Generate analysis report.

**Request**: JSON with analysis data
**ReSupported Formats**: WAV, MP3, FLAC, M4A, OGG
- **Audio Duration**: Processes first 2 seconds of audio
- **Python Version**: Requires Python 3.10+ (tested on 3.13)
- **Dependencies**: All required packages in `requirements.txt`

## ğŸ› ï¸ System Requirements

### Minimum Requirements
- **RAM**: 4GB
- **Storage**: 1GB free space
- **CPU**: Multi-core processor recommended

### Recommended Requirements
- **RAM**: 8GB+
- **Storage**: 2GB+ free space
- **GPU**: NVIDIA GPU with CUDA support (optional, for faster inference)
## âš ï¸ Important Notes

- **TensorFlow** - Deep learning framework
- **Librosa** - Audio processing library
- **Flask** - Web framework
- **ReportLab** - PDF generation
- **Bootstrap** - UI framework

## ğŸ”’ Security

- File validation and sanitization
- Secure file upload handling
- No data persistence (files deleted after processing)
- XSS and CSRF protection

## ğŸ“… Version History

- **v1.0.0** (January 2026) - Initial release with 90% accuracy
  - Advanced CNN model
  - Web interface with PDF reports
  - Real-time audio analysis

---

**Built with â¤ï¸ for combating deepfake audio**

**Last Updated:** January 2, 2026 - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“ Support

For questions and support, please open an issue in the repository.

## ğŸ™ Acknowledgments

- TensorFlow team for the ML framework
- Librosa team for audio processing
- Flask team for the web framework
- Bootstrap team for the UI framework

---

**Built with â¤ï¸ for combating deepfake audio**
